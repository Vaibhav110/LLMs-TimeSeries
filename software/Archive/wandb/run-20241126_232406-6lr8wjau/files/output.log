  0%|                                                                                                                             | 0/25000 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/home/vaibhav/miniconda3/envs/vai_llama/lib/python3.11/site-packages/triton/language/core.py", line 35, in wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/vaibhav/miniconda3/envs/vai_llama/lib/python3.11/site-packages/triton/language/core.py", line 1534, in dot
    return semantic.dot(input, other, acc, input_precision, max_num_imprecise_acc, out_dtype, _builder)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vaibhav/miniconda3/envs/vai_llama/lib/python3.11/site-packages/triton/language/semantic.py", line 1355, in dot
    assert_dtypes_valid(lhs.dtype, rhs.dtype, builder.options)
  File "/home/vaibhav/miniconda3/envs/vai_llama/lib/python3.11/site-packages/triton/language/semantic.py", line 1352, in assert_dtypes_valid
    assert lhs_dtype == rhs_dtype, f"First input ({lhs_dtype}) and second input ({rhs_dtype}) must have the same dtype!"
           ^^^^^^^^^^^^^^^^^^^^^^
AssertionError: First input (bf16) and second input (fp16) must have the same dtype!

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/vaibhav/LLMs-TimeSeries/software/Archive/LLM_finetune.py", line 113, in <module>
    main(args)
  File "/home/vaibhav/LLMs-TimeSeries/software/Archive/LLM_finetune.py", line 75, in main
    trainer_stats = trainer.train()
                    ^^^^^^^^^^^^^^^
  File "<string>", line 157, in train
  File "<string>", line 380, in _fast_inner_training_loop
  File "<string>", line 31, in _unsloth_training_step
  File "/home/vaibhav/miniconda3/envs/vai_llama/lib/python3.11/site-packages/unsloth/models/_utils.py", line 1028, in _unsloth_pre_compute_loss
    return self._old_compute_loss(model, inputs, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vaibhav/miniconda3/envs/vai_llama/lib/python3.11/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "/home/vaibhav/miniconda3/envs/vai_llama/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vaibhav/miniconda3/envs/vai_llama/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vaibhav/miniconda3/envs/vai_llama/lib/python3.11/site-packages/accelerate/utils/operations.py", line 823, in forward
    return model_forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vaibhav/miniconda3/envs/vai_llama/lib/python3.11/site-packages/accelerate/utils/operations.py", line 811, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vaibhav/miniconda3/envs/vai_llama/lib/python3.11/site-packages/torch/amp/autocast_mode.py", line 44, in decorate_autocast
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/vaibhav/miniconda3/envs/vai_llama/lib/python3.11/site-packages/torch/_compile.py", line 32, in inner
    return disable_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vaibhav/miniconda3/envs/vai_llama/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py", line 632, in _fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/vaibhav/miniconda3/envs/vai_llama/lib/python3.11/site-packages/unsloth/models/llama.py", line 1084, in PeftModelForCausalLM_fast_forward
    return self.base_model(
           ^^^^^^^^^^^^^^^^
  File "/home/vaibhav/miniconda3/envs/vai_llama/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vaibhav/miniconda3/envs/vai_llama/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vaibhav/miniconda3/envs/vai_llama/lib/python3.11/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vaibhav/miniconda3/envs/vai_llama/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vaibhav/miniconda3/envs/vai_llama/lib/python3.11/site-packages/unsloth/models/llama.py", line 986, in _CausalLM_fast_forward
    loss = fused_linear_cross_entropy(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vaibhav/miniconda3/envs/vai_llama/lib/python3.11/site-packages/unsloth_zoo/loss_utils.py", line 147, in fused_linear_cross_entropy
    loss = linear_cross_entropy(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/vaibhav/miniconda3/envs/vai_llama/lib/python3.11/site-packages/cut_cross_entropy/linear_cross_entropy.py", line 58, in linear_cross_entropy
    return cce_linear_cross_entropy(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vaibhav/miniconda3/envs/vai_llama/lib/python3.11/site-packages/cut_cross_entropy/cce.py", line 168, in cce_linear_cross_entropy
    return linear_cross_entropy_apply(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vaibhav/miniconda3/envs/vai_llama/lib/python3.11/site-packages/cut_cross_entropy/cce.py", line 125, in linear_cross_entropy_apply
    loss = LinearCrossEntropyFunction.apply(e, c, params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vaibhav/miniconda3/envs/vai_llama/lib/python3.11/site-packages/torch/autograd/function.py", line 575, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vaibhav/miniconda3/envs/vai_llama/lib/python3.11/site-packages/cut_cross_entropy/cce.py", line 46, in forward
    ret = cce_lse_forward_kernel(
          ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vaibhav/miniconda3/envs/vai_llama/lib/python3.11/site-packages/cut_cross_entropy/cce_lse_forward.py", line 182, in cce_lse_forward_kernel
    _cce_lse_forward_kernel[grid](
  File "/home/vaibhav/miniconda3/envs/vai_llama/lib/python3.11/site-packages/triton/runtime/jit.py", line 345, in <lambda>
    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vaibhav/miniconda3/envs/vai_llama/lib/python3.11/site-packages/triton/runtime/autotuner.py", line 338, in run
    return self.fn.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vaibhav/miniconda3/envs/vai_llama/lib/python3.11/site-packages/triton/runtime/autotuner.py", line 338, in run
    return self.fn.run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vaibhav/miniconda3/envs/vai_llama/lib/python3.11/site-packages/triton/runtime/jit.py", line 662, in run
    kernel = self.compile(
             ^^^^^^^^^^^^^
  File "/home/vaibhav/miniconda3/envs/vai_llama/lib/python3.11/site-packages/triton/compiler/compiler.py", line 276, in compile
    module = src.make_ir(options, codegen_fns, context)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vaibhav/miniconda3/envs/vai_llama/lib/python3.11/site-packages/triton/compiler/compiler.py", line 113, in make_ir
    return ast_to_ttir(self.fn, self, context=context, options=options, codegen_fns=codegen_fns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
triton.compiler.errors.CompilationError: at 60:16:

    accum = tl.zeros((BLOCK_B, BLOCK_V), dtype=tl.float32)
    for d in range(0, tl.cdiv(D, BLOCK_D)):
        # Load the next block of A and B, generate a mask by checking the K dimension.
        # If it is out of bounds, set it to 0.
        if EVEN_D:
            e = tl.load(e_ptrs)
            c = tl.load(c_ptrs)
        else:
            e = tl.load(e_ptrs, mask=offs_d[None, :] < D - d * BLOCK_D, other=0.0)
            c = tl.load(c_ptrs, mask=offs_d[:, None] < D - d * BLOCK_D, other=0.0)
        accum = tl.dot(e, c, accum, input_precision=DOT_PRECISION)
                ^
